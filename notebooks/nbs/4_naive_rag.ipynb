{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60525002ddf614db",
   "metadata": {},
   "source": [
    "# Demo for MedAgent - First answer generation with naive RAG pipeline\n",
    "\n",
    "This is the manual testing playground to test some basic workflows later properly implemented in the MedAgent repository.\n",
    "\n",
    "This file is responsible for a first test of answer generation with naive retrieval (basically creating the second baseline for our system test). This means, for the question first the most similar chunks from the guidelines are retrieved, and then provided to a generator with the original question. For this setup, new feedback must be gathered and the results analyzed and visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30139ef9da2d661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "from typing import List\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "from general.data_model.guideline_metadata import GuidelineMetadata\n",
    "from general.helper.mongodb_interactor import MongoDBInterface, CollectionName\n",
    "from general.helper.embedder import OpenAIEmbedder\n",
    "from general.helper.logging import logger\n",
    "from scripts.Guideline.guideline_interaction import get_plain_text_from_pdf\n",
    "from scripts.System.system_setup import load_system_json\n",
    "from scripts.System.system_interaction import init_workflow, init_workflow_with_id, init_chat, pose_question\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.local-env\")\n",
    "BACKEND_API_URL = \"http://host.docker.internal:5000/api\"\n",
    "mongo_url = os.getenv(\"MONGO_URL\", \"mongodb://mongo:mongo@host.docker.internal:27017/\")\n",
    "\n",
    "weaviate_db_config = load_system_json(\"./input/database_setups/weaviate_custom_vectorizer.json\")\n",
    "naive_rag_azure_config = load_system_json(\"./input/system/naive_rag_azure.json\")\n",
    "inserted_guidelines = load_system_json(\"./output/naive_rag/chunk_indexing.json\")\n",
    "text_output_dir = \"output/guideline/plain_text/\"\n",
    "for file_or_dir in [text_output_dir]:\n",
    "    os.makedirs(os.path.dirname(file_or_dir), exist_ok=True)\n",
    "\n",
    "dbi = MongoDBInterface(mongo_url)\n",
    "dbi.register_collections(\n",
    "    CollectionName.GUIDELINES,\n",
    "    CollectionName.WORKFLOW_SYSTEMS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5e9e53491be494",
   "metadata": {},
   "source": [
    "## Setup vector database\n",
    "In the first jupyter notebook, the guideline were already downloaded and stored in a MongoDB. To now be utilizable for the naive RAG flow, their content now needs to be cut up and stored in a vector database (for now Milvus with chunk size of 512)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc3dd3a-592f-4055-b947-e2207be757af",
   "metadata": {},
   "outputs": [],
   "source": [
    "guideline_documents = list(dbi.get_collection(CollectionName.GUIDELINES).find())\n",
    "guidelines = [\n",
    "    dbi.document_to_guideline_metadata(doc) for doc in guideline_documents\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af2ad42-fc5f-4dfc-aef4-06ee9a1b04ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment out if not want to overwrite\n",
    "response = requests.delete(f\"{BACKEND_API_URL}/knowledge/vector/retriever/delete/{weaviate_db_config['class_name']}\")\n",
    "logger.info(f\"Result of deletion for {weaviate_db_config['class_name']}: {response}\")\n",
    "\n",
    "response = requests.post(f\"{BACKEND_API_URL}/knowledge/vector/retriever/init\", json=weaviate_db_config)\n",
    "try:\n",
    "    response.raise_for_status()\n",
    "    logger.info(response)\n",
    "except Exception as e:\n",
    "    detail = response.json().get(\"detail\", \"\")\n",
    "    if \"already exists\" in detail:\n",
    "        logger.info(f\"Weaviate collection already exists: {detail}\")\n",
    "    else:\n",
    "        logger.error(f\"Failed to initialize Weaviate collection: {detail}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f4146a859e6c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedder = OpenAIEmbedder(\n",
    "#    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "#    api_base=os.getenv(\"AZURE_OPENAI_API_BASE\"),\n",
    "#    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "#    deployment_name=\"text-embedding-3-small\" # or later: text-embedding-3-small\n",
    "#)\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def chunk_text(text: str, max_tokens: int = 512) -> List[str]:\n",
    "    words = text.split()\n",
    "    chunks, current = [], []\n",
    "    token_count = lambda x: len(encoding.encode(\" \".join(x)))\n",
    "\n",
    "    for word in words:\n",
    "        current.append(word)\n",
    "        if token_count(current) >= max_tokens:\n",
    "            chunks.append(\" \".join(current[:-1]))\n",
    "            current = [word]\n",
    "    if current:\n",
    "        chunks.append(\" \".join(current))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f8fedc-b413-45ba-a362-b1d0a6ef1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_for_guideline(guideline: GuidelineMetadata):\n",
    "    logger.info(f\"Processing guideline {guideline.awmf_register_number} ({guideline.download_information.page_count} pages)\")\n",
    "    text = get_plain_text_from_pdf(guideline.download_information.file_path, text_output_dir)\n",
    "    chunks = chunk_text(text)\n",
    "    if chunks == []:\n",
    "        logger.error(f\"[{g.awmf_register_numner}] Something went wrong with reading the text or chunking -> empty\")\n",
    "    logger.progress(f\"Processing guideline {guideline.awmf_register_number} [PROGRESS]: \", 0, len(chunks))\n",
    "    non_successful_chunks = []\n",
    "    for i_c, chunk in enumerate(chunks):\n",
    "        try:\n",
    "            #vector = embedder.embed(chunk)\n",
    "            insert_entity = {\n",
    "                \"text\": chunk,\n",
    "                #\"vector\": vector,\n",
    "                \"metadata\": {\n",
    "                    \"guideline_id\": guideline.awmf_register_number,\n",
    "                    \"chunk_index\": i_c\n",
    "                },\n",
    "                \"class_name\": weaviate_db_config['class_name']\n",
    "            }\n",
    "            #logger.info(insert_entity)\n",
    "            response = requests.post(\n",
    "                f\"{BACKEND_API_URL}/knowledge/vector/retriever/insert\",\n",
    "                json = insert_entity\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "        except Exception as chunk_error:\n",
    "            logger.error(f\"[{g.awmf_register_number}] Failed to process chunk {i_c}: {chunk_error}\")\n",
    "            non_successful_chunks.append({i_c: chunk})\n",
    "        \n",
    "        logger.progress(f\"Processing guideline {guideline.awmf_register_number} [PROGRESS]:\", i_c+1, len(chunks))\n",
    "\n",
    "    if non_successful_chunks != []:\n",
    "        logger.error(f\"Problems with inserting these chunks: {non_successful_chunks}\")\n",
    "    else:\n",
    "        logger.success(f\"Successfully transferred whole guideline with {len(chunks)} chunks\")\n",
    "\n",
    "def insert_batch_for_guideline(guideline: GuidelineMetadata):\n",
    "    logger.info(f\"Processing guideline {guideline.awmf_register_number} ({guideline.download_information.page_count} pages)\")\n",
    "    text = get_plain_text_from_pdf(guideline.download_information.file_path, text_output_dir)\n",
    "    chunks = chunk_text(text)\n",
    "    if chunks == []:\n",
    "        logger.error(f\"[{g.awmf_register_numner}] Something went wrong with reading the text or chunking -> empty\")\n",
    "    logger.progress(f\"Tranforming chunks {guideline.awmf_register_number} [PROGRESS]: \", 0, len(chunks))\n",
    "\n",
    "    batch_entities = []\n",
    "    for i_c, chunk in enumerate(chunks):\n",
    "        #vector = embedder.embed(chunk)\n",
    "        insert_entity = {\n",
    "            \"text\": chunk,\n",
    "            #\"vector\": vector,\n",
    "            \"metadata\": {\n",
    "                \"guideline_id\": guideline.awmf_register_number,\n",
    "                \"chunk_index\": i_c\n",
    "            },\n",
    "            \"class_name\": weaviate_db_config['class_name']\n",
    "        }\n",
    "        batch_entities.append(insert_entity)\n",
    "        logger.progress(f\"Tranforming chunks {guideline.awmf_register_number} [PROGRESS]: \", i_c+1, len(chunks))\n",
    "\n",
    "    logger.info(f\"Submitting batch upload\")\n",
    "    response = requests.post(\n",
    "        f\"{BACKEND_API_URL}/knowledge/vector/retriever/insertBatch\",\n",
    "        json = {\n",
    "            \"class_name\": weaviate_db_config['class_name'],\n",
    "            \"entries\": batch_entities\n",
    "        }\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    logger.info(f\"Response: {response.json()}\")\n",
    "    return response.json(), len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590869e8-64de-43a3-8a59-62fe4c5b8699",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(guidelines)):\n",
    "    if i in inserted_guidelines.keys():\n",
    "        continue\n",
    "\n",
    "    res, num_chunks = insert_batch_for_guideline(guidelines[i])\n",
    "    inserted_guidelines[i] = {\n",
    "        \"guideline_awmf_nr\": guidelines[i].awmf_register_number,\n",
    "        \"number_pages\": guidelines[i].download_information.page_count,\n",
    "        \"number_chunks\": num_chunks,\n",
    "        \"missing_chunks\": res[\"failed\"]\n",
    "    }\n",
    "    print(inserted_guidelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf24818fc5f0b633",
   "metadata": {},
   "source": [
    "## Test out question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b283e323b3ee23cb",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "naive_rag_azure_wf = dbi.get_entry(CollectionName.WORKFLOW_SYSTEMS, \"name\", naive_rag_azure_config[\"name\"])\n",
    "if naive_rag_azure_wf is None:\n",
    "    naive_rag_azure_wf_id = init_workflow(BACKEND_API_URL, naive_rag_azure_config)\n",
    "else:\n",
    "    naive_rag_azure_wf_id = dbi.document_to_workflow_system(naive_rag_azure_wf).workflow_id\n",
    "    naive_rag_azure_wf_id = init_workflow_with_id(BACKEND_API_URL, naive_rag_azure_config, naive_rag_azure_wf_id)\n",
    "\n",
    "naive_rag_azure_chat = init_chat(BACKEND_API_URL, naive_rag_azure_wf_id)\n",
    "question = dbi.get_collection(CollectionName.QUESTIONS).find_one().get(\"question\")\n",
    "answer, response_latency = pose_question(BACKEND_API_URL, naive_rag_azure_chat, question)\n",
    "\n",
    "print(f\"### QUESTION: ###\\n{question}\")\n",
    "print(f\"--------------------------------------------------\")\n",
    "print(f\"### ANSWER in {response_latency:.2f} seconds: ###\\n{answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
